<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<!-- saved from url=(0076)http://www.cs.huji.ac.il/~raananf/projects/lss_upscale/sup_images/index.html -->
<HTML xmlns="http://www.w3.org/1999/xhtml"><HEAD><TITLE>OPINENet</TITLE>
<META content="text/html; charset=iso-8859-1" http-equiv=Content-Type>
<SCRIPT type=text/javascript>
<!--

<!--
function selectImage(_this,image)
{
	var d=document;
	image.src=_this.src;
	image.parentNode.href=_this.src;
	image.style.borderColor=_this.style.borderColor;
}
function setBorder(image)
{
	if (image.src.indexOf('org.png')!=-1)
	{
		image.style.borderColor='gray';
	}
	if (image.src.indexOf('KR.png')!=-1)
	{
		image.style.borderColor='#FF8C00';
	}
	if (image.src.indexOf('MCA.png')!=-1)
	{
		image.style.borderColor='#1E90FF';
	}
	if (image.src.indexOf('JSM.png')!=-1)
	{
		image.style.borderColor='red';
	}
	if (image.src.indexOf('FOE.png')!=-1)
	{
		image.style.borderColor='#0033FF';
	}
	if (image.src.indexOf('BP.png')!=-1)
	{
		image.style.borderColor='#FFDD00';
	}
	if (image.src.indexOf('SALSA.png')!=-1)
	{
		image.style.borderColor='#009933';
	}
	if (image.src.indexOf('gf.png')!=-1)
	{
		image.style.borderColor='#FF0050';
	}
	if (image.src.indexOf('Org.png')!=-1)
	{
		image.style.borderColor='#0099CC';
	}
	if (image.src.indexOf('IFASDA.png')!=-1)
	{
		image.style.borderColor='#FF8C00';
	}
	if (image.src.indexOf('TV.png')!=-1)
	{
		image.style.borderColor='#1E90FF';
	}
}


-->
//-->
</SCRIPT>

<STYLE type=text/css>
IMG.thumbnail {
	BORDER-BOTTOM-STYLE: solid; BORDER-RIGHT-STYLE: solid; BORDER-TOP-STYLE: solid; HEIGHT: 128px; BORDER-LEFT-STYLE: solid
}
P.thumbnail_title {
	MARGIN-TOP: 30px; MARGIN-BOTTOM: 0px; FONT-SIZE: 12px
}
IMG {
	BORDER-BOTTOM-STYLE: solid; BORDER-BOTTOM-COLOR: gray; BORDER-RIGHT-STYLE: solid; BORDER-TOP-COLOR: gray; MAX-WIDTH: 800px; BORDER-TOP-STYLE: solid; BORDER-RIGHT-COLOR: gray; BORDER-LEFT-STYLE: solid; BORDER-LEFT-COLOR: gray
}
BODY {
	TEXT-ALIGN: left; FONT-FAMILY: Arial; COLOR: #4f4f4f; FONT-SIZE: 14px
}
H1 {
	FONT-SIZE: 30px; FONT-WEIGHT: normal
}
H2 {
	FONT-SIZE: 25px; FONT-WEIGHT: normal
}
H3 {
	MARGIN-TOP: 60px; FONT-SIZE: 25px
}
H4 {
	MARGIN-TOP: 60px; FONT-SIZE: 25px
}
A {
	FONT-VARIANT: normal; FONT-STYLE: normal; COLOR: #4f4f4f; FONT-WEIGHT: bold; TEXT-DECORATION: none
}
A:hover {
	COLOR: green;
	text-decoration: none;
}
.contents {
	TEXT-ALIGN: left; FONT-SIZE: 18px
}
.STYLE2 {
	font-size: 26px;
	font-weight: bold;
}
.STYLE3 {font-size: 18px}
.STYLE5 {font-size: 16px}
a:link {
	color: #0066FF;
	text-decoration: underline;
}
a:visited {
	text-decoration: underline;
}
a:active {
	text-decoration: underline;
}
.STYLE14 {font-size: 14px}
.STYLE17 {font-size: 15px}
.STYLE28 {color: #CC3300}
.STYLE30 {
	font-size: 16px;
	font-weight: bold;
	color: #E04503;
}
</STYLE>

<META name=GENERATOR content="MSHTML 8.00.6001.18702"></HEAD>
<BODY>
<CENTER>
  <H1 class="STYLE2"><br>
    <a name="PageTop"></a><span class="STYLE28"> Optimization-Inspired Compact Deep Compressive Sensing</span> </H1>
  <H2><span class="STYLE3">Jian Zhang, Chen Zhao, Wen Gao </span></H2>
</CENTER>
<BLOCKQUOTE>
  <P align="justify"><strong>Abstract</strong>&mdash;In order to improve CS performance of natural images, in this paper, we propose a novel framework to design an OPtimization-INspired Explicable deep Network, dubbed OPINE-Net, for adaptive sampling and recovery. Both orthogonal and binary constraints of sampling matrix are incorporated into OPINE-Net simultaneously. In particular, OPINE-Net is composed of three subnets: sampling subnet, initialization subnet and recovery subnet, and all the parameters in OPINE-Net (\eg sampling matrix, nonlinear transforms, shrinkage threshold) are learned end-to-end, rather than hand-crafted. Moreover, considering the relationship among neighboring blocks, an enhanced version OPINE-Net$^+$ is developed,  which allows image blocks to be sampled independently but reconstructed jointly to further enhance the performance. In addition, some interesting findings of learned sampling matrix are presented. Compared with existing state-of-the-art network-based CS methods, the proposed hardware-friendly OPINE-Nets not only achieve better performance but also require much fewer parameters and much less storage space, while maintaining a real-time running speed.</P>
  <P align="justify">&nbsp;</P>
  <P align="center"><span class="STYLE2"><img src="./Figs/OPINE_NET.png" width="1000" height="250" border="0"></span></P>
  <P align="center"> Fig. Illustrations of our proposed OPINE-net framework. Specifically, OPINE-Net is composed of three subnets: Sampling Subnet (SS), Initialization<br>
  Subnet (IS) and Recovery Subnet (RS). </P>
  <P align="center"><span class="STYLE2"><img src="./Figs/OPINE_NET_plus.png" width="1000" height="250" border="0"></span></P>
  <P align="center"> Illustrations of our proposed OPINE-Net+ framework, which allows image blocks to be sampled independently but recovered jointly, greatly suppressing<br>
    blocking artifacts. <br>
</P>
  <P align="center"><span class="STYLE2"><img src="./Figs/visual_BI_New.png" width="1000" height="500" border="0"></span><br>
    <br>
    Fig. Visual comparison of all the competing CS methods.   <br>
</P>
  <P align="justify" class="STYLE30">Paper: </P>
  <P align="justify" class="STYLE5"><span class="STYLE17"><strong>Optimization-Inspired Compact Deep Compressive Sensing</strong><br>
    J. Zhang, C. Zhao, W. Gao <br>
    <em> JSTSP 2020 </em><br>
    <span class="STYLE14"><a href="https://jianzhang.tech/papers/JSTSP2020-OPINE-Net.pdf">[PDF]</a>&#12288;</span></span><a href="https://github.com/jianzhangcs/OPINE-Net" class="STYLE14">[PyTorch Code]</a></P>
  <P align="justify" class="STYLE5">&nbsp;</P>
  <P align="justify" class="STYLE5">&nbsp;</P>
</BLOCKQUOTE>
</BODY></HTML>
